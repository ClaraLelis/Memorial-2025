{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38605f9",
   "metadata": {},
   "source": [
    "# <font color=purple><center> Stop right now, thank you very much!\n",
    "    \n",
    "### <font color=violet><center>Maria Clara Macêdo Lelis\n",
    "    \n",
    "    \n",
    "<font color=green> Neste notebook iremos utilizar uma MLP feita com `Pytorch` para entender e implementar uma estratégia de parada antecipada. A rede será treinada e testada com o dataset `diamonds` da biblioteca `seaborn`.\n",
    "    \n",
    "    \n",
    "    \n",
    "<font color=green>O primeito passo é importar todas as bibliotecas a serem utilizadas. Depois carregamos o dataset a ser utilizado e realizamos um split de treino, teste e validação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3279c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebfd431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat    cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23  Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= sb.load_dataset('diamonds')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d566be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAMANHO_TEST_VAL = 0.3\n",
    "TAMANHO_VAL = 0.5\n",
    "SEMENTE_ALEATORIA1 = 135790\n",
    "SEMENTE_ALEATORIA2 = 135791\n",
    "\n",
    "indices = df.index\n",
    "indices_treino, indices_teste_val = train_test_split(indices, test_size=TAMANHO_TEST_VAL, random_state=SEMENTE_ALEATORIA1)\n",
    "\n",
    "df_treino = df.loc[indices_treino]\n",
    "df_teste_val = df.loc[indices_teste_val]\n",
    "\n",
    "atr_treino = df_treino[[\"depth\",\"table\",\"price\",\"x\",\"y\",\"z\"]]\n",
    "target_treino = df_treino[\"carat\"]\n",
    "\n",
    "indices = df_teste_val.index\n",
    "indices_teste, indices_val = train_test_split(indices, test_size=TAMANHO_VAL, random_state=SEMENTE_ALEATORIA2)\n",
    "\n",
    "df_teste = df.loc[indices_teste]\n",
    "df_val = df.loc[indices_val]\n",
    "\n",
    "atr_teste = df_teste[[\"depth\",\"table\",\"price\",\"x\",\"y\",\"z\"]]\n",
    "target_teste = df_teste[\"carat\"]\n",
    "\n",
    "atr_val = df_val[[\"depth\",\"table\",\"price\",\"x\",\"y\",\"z\"]]\n",
    "target_val = df_val[\"carat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c23479",
   "metadata": {},
   "source": [
    "<font color=green> Antes de criar a nossa rede precisamos transformar os dataframes do `pandas` em tensores pois o `pytorch` não realiza operações com dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3839d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino_tensor = torch.tensor(atr_treino.values, dtype=torch.float32)\n",
    "y_treino_tensor = torch.tensor(target_treino.values, dtype=torch.long)\n",
    "\n",
    "X_val_tensor = torch.tensor(atr_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(target_val.values, dtype=torch.long)\n",
    "\n",
    "num_classes = len(torch.unique(y_treino_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee026f60",
   "metadata": {},
   "source": [
    "<font color=green> Agora podemos utilizar a biblioteca `Pytorch` para definir a nossa rede neural na classe MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5445b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.camadas=nn.Sequential(\n",
    "            nn.Linear(6, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.camadas(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451bcee3",
   "metadata": {},
   "source": [
    "<font color=green>Então podemos treinar uma rede neural MLP, usando o otimizador SGD e a função de perda CrossEntropyLoss. A cada época, ele calcula a saída da rede, mede o erro (perda), ajusta os pesos com base nesse erro e avalia o desempenho em dados de validação. Se a perda de validação melhorar, o modelo continua; caso contrário, ele conta quantas épocas se passaram sem melhora. Se esse número atingir o limite definido pela variável paciencia, o treinamento é interrompido mais cedo para evitar overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c31fda4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0, Val Loss: 1142.2720\n",
      "Parando cedo por falta de melhora.\n"
     ]
    }
   ],
   "source": [
    "minha_mlp = MLP()\n",
    "TAXA_DE_APRENDIZADO=0.001\n",
    "otimizador = optim.SGD(minha_mlp.parameters(), lr=TAXA_DE_APRENDIZADO)\n",
    "num_epocas = 1000\n",
    "melhor_val_loss = float('inf')\n",
    "paciencia = 10\n",
    "epocas_sem_melhora = 0\n",
    "criterio = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoca in range(num_epocas):\n",
    "    minha_mlp.train()\n",
    "    otimizador.zero_grad()\n",
    "    saida = minha_mlp(X_treino_tensor)\n",
    "    perda = criterio(saida, y_treino_tensor)\n",
    "    perda.backward()\n",
    "    otimizador.step()\n",
    "    \n",
    "    minha_mlp.eval()\n",
    "    with torch.no_grad():\n",
    "        val_saida = minha_mlp(X_val_tensor)\n",
    "        val_perda = criterio(val_saida, y_val_tensor)\n",
    "    \n",
    "    if epoca %100==0:\n",
    "        print(f'Época {epoca}, Val Loss: {val_perda.item():.4f}')\n",
    "    \n",
    "    if val_perda.item()<melhor_val_loss:\n",
    "        melhor_val_loss=val_perda.item()\n",
    "        epocas_sem_melhora=0\n",
    "    else:\n",
    "        epocas_sem_melhora+=1\n",
    "        if epocas_sem_melhora>=paciencia:\n",
    "            print(\"Parando cedo por falta de melhora.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6015f900",
   "metadata": {},
   "source": [
    "<font color= green>Podemos observar que esse tipo de abordagem é uma maneira eficiente de treinar uma rede neural evitando overfiting e o gasto computacional com modelos que possuem um desempenho subótimo.\n",
    "    \n",
    "    \n",
    "<font color= green> Referências\n",
    "    \n",
    "- Material de aula"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
